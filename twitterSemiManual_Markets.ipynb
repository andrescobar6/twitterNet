{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702b9cf5",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484d0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import math\n",
    "import ccxt\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import google.cloud\n",
    "import tweepy as tw\n",
    "from pandas_gbq import gbq\n",
    "import matplotlib.cm as cm\n",
    "from boruta import BorutaPy\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import bigquery\n",
    "from sklearn import preprocessing\n",
    "from requests import Request, Session\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
    "\n",
    "#_____\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b2ab84",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5dc123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCION QUE LEE EL ARCHIVO CONFIG\n",
    "def get_config(category, key):\n",
    "    \n",
    "    global config\n",
    "    return config[category][key]\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCION QUE GENERA CONEXION CON ARCHIVO CONFIG\n",
    "def updateConfig(config_name):\n",
    "    \n",
    "    global config\n",
    "    \n",
    "    config = configparser.ConfigParser()\n",
    "    config.sections()\n",
    "    config.read(config_name)\n",
    "    \n",
    "#_____\n",
    "\n",
    "#FUNCION QUE GRAFICA POR COLORES SEGUN COMPRAS Y NO COMRPAS\n",
    "def plot_colourline(x,y,c):\n",
    "    c = c\n",
    "    ax = plt.gca()\n",
    "    for i in np.arange(len(x)-1):\n",
    "        ax.plot([x[i],x[i+1]], [y[i],y[i+1]], c=c[i])\n",
    "    return\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCION QUE ESCRIBE PICKLE DE VARIABLE\n",
    "def writePickleVariable(variable,variable_name):\n",
    "    pickle_out = open(variable_name+\".pickle\",\"wb\")\n",
    "    pickle.dump(variable, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "#_____\n",
    "    \n",
    "#FUNCION QUE LEE PICKLE DE VARIABLE\n",
    "def readPickleVariable(variable_name):    \n",
    "    return pickle.load(open(variable_name+\".pickle\",\"rb\"))\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCION QUE REDONDEA FLOAT HACIA ABAJO SEGUN DECIMALES\n",
    "def round_decimals_down(number:float, decimals:int=2):\n",
    "    \"\"\"\n",
    "    Returns a value rounded down to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more\")\n",
    "    elif decimals == 0:\n",
    "        return math.floor(number)\n",
    "\n",
    "    factor = 10 ** decimals\n",
    "    return math.floor(number * factor) / factor\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCION QUE REDONDEA FLOAT HACIA ARRIBA SEGUN DECIMALES\n",
    "def round_decimals_up(number:float, decimals:int=2):\n",
    "    \"\"\"\n",
    "    Returns a value rounded down to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more\")\n",
    "    elif decimals == 0:\n",
    "        return math.ceil(number)\n",
    "\n",
    "    factor = 10 ** decimals\n",
    "    return math.ceil(number * factor) / factor\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCION QUE DESCARGA BASE DE DATOS DE MERCADO DE BIGQUERY\n",
    "def downloadDataBaseBigQuery(market_model,time,rows=None):\n",
    "    \n",
    "    #_____GOOGLE CLOUD CONECTION\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/bigQueryAccess.json\"\n",
    "\n",
    "    #_____SI NO SE DA UN NUMERO ESPECIFICO DE FILAS POR PARAMETRO\n",
    "    if rows==None:\n",
    "\n",
    "        #_____DESCARGAR BASE DE DATOS\n",
    "        candlesDataBase_BigQuery=gbq.read_gbq(\"SELECT * FROM [dogwood-terra-308100:surfNet.\"+market_model.replace(\"/\",\"_\")+\"] ORDER BY TIME DESC\",project_id=\"dogwood-terra-308100\",dialect=\"legacy\").sort_values(by=\"TIME\")\n",
    "        candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    else:\n",
    "\n",
    "        #_____DESCARGAR BASE DE DATOS\n",
    "        candlesDataBase_BigQuery=gbq.read_gbq(\"SELECT * FROM [dogwood-terra-308100:surfNet.\"+market_model.replace(\"/\",\"_\")+\"] ORDER BY TIME DESC LIMIT \"+str(rows),project_id=\"dogwood-terra-308100\",dialect=\"legacy\").sort_values(by=\"TIME\")\n",
    "        candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    candlesDataBase_BigQuery.OPEN=candlesDataBase_BigQuery.OPEN.astype(float)\n",
    "    candlesDataBase_BigQuery.HIGH=candlesDataBase_BigQuery.HIGH.astype(float)\n",
    "    candlesDataBase_BigQuery.LOW=candlesDataBase_BigQuery.LOW.astype(float)\n",
    "    candlesDataBase_BigQuery.CLOSE=candlesDataBase_BigQuery.CLOSE.astype(float)\n",
    "    candlesDataBase_BigQuery.VOLUME=candlesDataBase_BigQuery.VOLUME.astype(float)\n",
    "\n",
    "    #_____REESTRUCTURAR BASE DE DATOS\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    if time != \"1\":\n",
    "\n",
    "        #_____UPDATE CONFIG PREDICTION\n",
    "        updateConfig(\"semiManual.ini\")\n",
    "\n",
    "        #_____CREAR COLUMNAS\n",
    "        candlesDataBase_BigQuery_copy=candlesDataBase_BigQuery.copy()\n",
    "        candlesDataBase_BigQuery_copy=candlesDataBase_BigQuery_copy.set_index('TIME')\n",
    "        candlesDataBase_BigQuery_copy_total=candlesDataBase_BigQuery_copy[[\"ID\"]].groupby(pd.Grouper(freq=time+'min', offset=time+'min')).min()\n",
    "        candlesDataBase_BigQuery_copy_total=candlesDataBase_BigQuery_copy_total.join(candlesDataBase_BigQuery_copy[[\"VOLUME\"]].groupby(pd.Grouper(freq=time+'min', offset=time+'min')).sum())\n",
    "        candlesDataBase_BigQuery_copy_total=candlesDataBase_BigQuery_copy_total.join(candlesDataBase_BigQuery_copy[[\"LOW\"]].groupby(pd.Grouper(freq=time+'min', offset=time+'min')).min())\n",
    "        candlesDataBase_BigQuery_copy_total=candlesDataBase_BigQuery_copy_total.join(candlesDataBase_BigQuery_copy[[\"HIGH\"]].groupby(pd.Grouper(freq=time+'min', offset=time+'min')).max())\n",
    "\n",
    "        #_____AGREAR DATOS\n",
    "        for i in list(candlesDataBase_BigQuery_copy_total.index.values):\n",
    "            try:\n",
    "                candlesDataBase_BigQuery_copy_total.at[i,\"OPEN\"]=candlesDataBase_BigQuery.loc[candlesDataBase_BigQuery.TIME==i][\"OPEN\"].values[0]\n",
    "                final_time = i + np.timedelta64(int(time),'m')\n",
    "                if final_time in list(candlesDataBase_BigQuery_copy_total.index.values):\n",
    "                    candlesDataBase_BigQuery_copy_total.at[i,\"CLOSE\"]=candlesDataBase_BigQuery.loc[candlesDataBase_BigQuery.TIME==final_time][\"OPEN\"].values[0]\n",
    "                else:\n",
    "                    candlesDataBase_BigQuery_copy_total.at[i,\"CLOSE\"]=candlesDataBase_BigQuery.at[len(candlesDataBase_BigQuery)-1,\"CLOSE\"]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        #_____RESET INDEX\n",
    "        candlesDataBase_BigQuery_copy_total.reset_index(level=['TIME'],inplace=True)\n",
    "\n",
    "        #_____COLUMNA MARKET\n",
    "        for i in range(0,len(candlesDataBase_BigQuery_copy_total)):\n",
    "            candlesDataBase_BigQuery_copy_total.at[i,\"MARKET\"]=candlesDataBase_BigQuery.MARKET.values[0]\n",
    "\n",
    "        #_____ORDENAR COLUMNAS\n",
    "        column_names = list(candlesDataBase_BigQuery.columns)\n",
    "        candlesDataBase_BigQuery_copy_total = candlesDataBase_BigQuery_copy_total.reindex(columns=column_names)\n",
    "        candlesDataBase_BigQuery_copy_total.dropna(inplace=True)\n",
    "        candlesDataBase_BigQuery_copy_total.reset_index(inplace=True,drop=True)\n",
    "        candlesDataBase_BigQuery=candlesDataBase_BigQuery_copy_total.copy()\n",
    "\n",
    "    #_____RETURN\n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCION QUE DEVUELVE EL RSI DADO UN PERIODO DETERMINADO\n",
    "def RSI(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global config\n",
    "    updateConfig(\"semiManual.ini\")\n",
    "    \n",
    "    series=pd.Series(list(candlesDataBase_BigQuery.CLOSE.values))\n",
    "    period=int(get_config(\"PARAMETERS\",\"RSI_LEN\"))\n",
    "    \n",
    "    delta = series.diff().dropna()\n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n",
    "    u = u.drop(u.index[:(period-1)])\n",
    "    d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n",
    "    d = d.drop(d.index[:(period-1)])\n",
    "    rs = pd.DataFrame.ewm(u, com=period-1, adjust=False).mean() / \\\n",
    "         pd.DataFrame.ewm(d, com=period-1, adjust=False).mean()\n",
    "    \n",
    "    rsi=100 - 100 / (1 + rs)\n",
    "    \n",
    "    for i in list(rsi.index.values):\n",
    "        candlesDataBase_BigQuery.at[i,\"RSI\"]=rsi[i]\n",
    "                                        \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCION QUE CALCULA MACD\n",
    "def MACD(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global config\n",
    "    updateConfig(\"semiManual.ini\")\n",
    "    \n",
    "    close_data_df=candlesDataBase_BigQuery.copy()\n",
    "    close_data_df.CLOSE=close_data_df.CLOSE.astype(float)\n",
    "    close_data_df=close_data_df[[\"CLOSE\"]]\n",
    "    \n",
    "    #_____CREAR VARIABLE MACD\n",
    "    macd_12 = close_data_df.ewm(span=int(get_config(\"PARAMETERS\",\"MACD_SHORT\")), adjust=False).mean()\n",
    "    macd_26 = close_data_df.ewm(span=int(get_config(\"PARAMETERS\",\"MACD_LONG\")), adjust=False).mean()\n",
    "    macd = macd_12 - macd_26\n",
    "    macd_9 = macd.ewm(span=int(get_config(\"PARAMETERS\",\"MACD_TRIGGER\")), adjust=False).mean()\n",
    "\n",
    "    #_____AGREGAR VARIABLES A LA BASE DE DATOS\n",
    "    candlesDataBase_BigQuery[\"MACD\"]=macd\n",
    "    #candlesDataBase_BigQuery[\"MACD_\"+get_config(\"PARAMETERS\",\"MACD_SHORT\")]=macd_12\n",
    "    #candlesDataBase_BigQuery[\"MACD_\"+get_config(\"PARAMETERS\",\"MACD_LONG\")]=macd_26\n",
    "    candlesDataBase_BigQuery[\"MACD_TRIGGER\"]=macd_9\n",
    "    \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCION QUE BRINDA LOS NIVELES DE FIBONACCI\n",
    "def fibonacciLevels(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global config\n",
    "    global fractal\n",
    "    \n",
    "    #_____UPDATE CONFIG PREDICTION\n",
    "    updateConfig(\"semiManual.ini\")\n",
    "    \n",
    "    #_____ACTUALIZAR PARAMETROS\n",
    "    FIBONACCI_PERIOD=int(int(get_config(\"PARAMETERS\",\"FIBONACCI_PERIOD\"))/int(fractal))\n",
    "\n",
    "    #_____RECORRER DATOS DE TEST\n",
    "    for i in range(FIBONACCI_PERIOD,len(candlesDataBase_BigQuery)):\n",
    "        \n",
    "        #_____FIBONACCI\n",
    "        lows=list(candlesDataBase_BigQuery[i-FIBONACCI_PERIOD:i].LOW.values)\n",
    "        highs=list(candlesDataBase_BigQuery[i-FIBONACCI_PERIOD:i].HIGH.values)\n",
    "        Price_Min = min(lows)\n",
    "        Price_Max = max(highs)\n",
    "        Diff = Price_Max-Price_Min\n",
    "        level1 = Price_Max - 0.236 * Diff\n",
    "        level2 = Price_Max - 0.382 * Diff\n",
    "        level3 = Price_Max - 0.618 * Diff\n",
    "        level4 = Price_Max - 0.786 * Diff\n",
    "        \n",
    "        candlesDataBase_BigQuery.at[i,\"FIBO_LEVEL_1\"]=level1\n",
    "        candlesDataBase_BigQuery.at[i,\"FIBO_LEVEL_2\"]=level2\n",
    "        candlesDataBase_BigQuery.at[i,\"FIBO_LEVEL_3\"]=level3\n",
    "        candlesDataBase_BigQuery.at[i,\"FIBO_LEVEL_4\"]=level4\n",
    "            \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCION QUE CALCULA MACD\n",
    "def LAGS(candlesDataBase_BigQuery):\n",
    "    \n",
    "    for j in list(candlesDataBase_BigQuery.columns)[3:]:\n",
    "        candlesDataBase_BigQuery[j+\"_1\"]=candlesDataBase_BigQuery[j].shift(1)\n",
    "        candlesDataBase_BigQuery[j+\"_2\"]=candlesDataBase_BigQuery[j].shift(2)\n",
    "        candlesDataBase_BigQuery[j+\"_3\"]=candlesDataBase_BigQuery[j].shift(3)\n",
    "        \n",
    "    candlesDataBase_BigQuery.dropna(inplace=True)\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "        \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#CREATE VARIABLES\n",
    "def variableCreation(candlesDataBase_BigQuery):\n",
    "    \n",
    "    global fractal\n",
    "    updateConfig(\"semiManual.ini\")\n",
    "    \n",
    "    candlesDataBase_BigQuery=RSI(candlesDataBase_BigQuery)\n",
    "    candlesDataBase_BigQuery=MACD(candlesDataBase_BigQuery)\n",
    "    #candlesDataBase_BigQuery=fibonacciLevels(candlesDataBase_BigQuery)\n",
    "    #candlesDataBase_BigQuery=LAGS(candlesDataBase_BigQuery)\n",
    "    \n",
    "    candlesDataBase_BigQuery.dropna(inplace=True)\n",
    "    candlesDataBase_BigQuery.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    return candlesDataBase_BigQuery\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCION QUE HACE BACKTESTING PARA DETERMINAR MEJORES PARAMETROS TOPES DE VENTA\n",
    "def backtesting(test_sample):\n",
    "    \n",
    "    global fractal\n",
    "    global final_df\n",
    "    global utility_df\n",
    "    global train_model\n",
    "    global tradingBook\n",
    "    global market_model\n",
    "    global train_sample\n",
    "    global backtestingDataFrame\n",
    "    global distance\n",
    "    global angle\n",
    "    global rsi_15\n",
    "    global rsi_30\n",
    "    global rsi_60\n",
    "    global takeprofit\n",
    "    global stoploss\n",
    "    \n",
    "    #_____UPDATE CONFIG PREDICTION\n",
    "    updateConfig(\"semiManual.ini\")\n",
    "    \n",
    "    #_____INICIAR LISTAS\n",
    "    TP_LIST=ast.literal_eval(get_config(\"PARAMETERS_BACKTESTING\",\"TP_LIST\"))\n",
    "    SL_LIST=ast.literal_eval(get_config(\"PARAMETERS_BACKTESTING\",\"SL_LIST\"))\n",
    "    \n",
    "    PRECENTIL_DISTANCE_MACD_TRIGGER=ast.literal_eval(get_config(\"PARAMETERS_BACKTESTING\",\"PRECENTIL_DISTANCE_MACD_TRIGGER\"))\n",
    "    PRECENTIL_ANGLE_MACD_TRIGGER=ast.literal_eval(get_config(\"PARAMETERS_BACKTESTING\",\"PRECENTIL_ANGLE_MACD_TRIGGER\"))\n",
    "    RSI_15=ast.literal_eval(get_config(\"PARAMETERS_BACKTESTING\",\"RSI_15\"))\n",
    "    RSI_30=ast.literal_eval(get_config(\"PARAMETERS_BACKTESTING\",\"RSI_30\"))\n",
    "    RSI_60=ast.literal_eval(get_config(\"PARAMETERS_BACKTESTING\",\"RSI_60\"))\n",
    "    \n",
    "    #_____INICIALIZAR BASE DE DATOS DE SIMULACION DE UTILIDAD\n",
    "    utility_df=pd.DataFrame()\n",
    "    \n",
    "    #_____FOR LOOP\n",
    "    for distance in PRECENTIL_DISTANCE_MACD_TRIGGER:\n",
    "        for angle in PRECENTIL_ANGLE_MACD_TRIGGER:\n",
    "            for rsi_15 in RSI_15:\n",
    "                for rsi_30 in RSI_30:\n",
    "                    for rsi_60 in RSI_60:\n",
    "                        for takeprofit in TP_LIST:\n",
    "                            for stoploss in SL_LIST:\n",
    "            \n",
    "                                #_____GENERAR VARIABLES DE DECISION\n",
    "                                candlesDataBase_BigQuery_Signal_COPY=test_sample.copy()\n",
    "\n",
    "                                #\n",
    "\n",
    "                                #CUANDO DISTANCIA ENTRE MACD Y TRIGGER ESTE EN PERCENTIL 10\n",
    "                                candlesDataBase_BigQuery_Signal_COPY=candlesDataBase_BigQuery_Signal_COPY.loc[(candlesDataBase_BigQuery_Signal_COPY.HIST_MACD_VS_TRIGGER_15<=np.quantile(list(candlesDataBase_BigQuery_Signal_COPY.HIST_MACD_VS_TRIGGER_15.values),float(distance[1])))&(candlesDataBase_BigQuery_Signal_COPY.HIST_MACD_VS_TRIGGER_15>=np.quantile(list(candlesDataBase_BigQuery_Signal_COPY.HIST_MACD_VS_TRIGGER_15.values),float(distance[0])))]\n",
    "                                candlesDataBase_BigQuery_Signal_COPY.reset_index(inplace=True,drop=True)\n",
    "\n",
    "                                #ANGULO 15 ESTE SOBRE PERCENTIL 90\n",
    "                                candlesDataBase_BigQuery_Signal_COPY=candlesDataBase_BigQuery_Signal_COPY.loc[candlesDataBase_BigQuery_Signal_COPY.ANGLE_MACD_VS_TRIGGER_15>=np.quantile(list(candlesDataBase_BigQuery_Signal_COPY[\"ANGLE_MACD_VS_TRIGGER_15\"].values),float(angle))]\n",
    "                                candlesDataBase_BigQuery_Signal_COPY.reset_index(inplace=True,drop=True)\n",
    "\n",
    "                                #RSI 15 ESTE POR DEBAJO DE 50\n",
    "                                candlesDataBase_BigQuery_Signal_COPY=candlesDataBase_BigQuery_Signal_COPY.loc[candlesDataBase_BigQuery_Signal_COPY.RSI_15<=float(rsi_15)]\n",
    "                                candlesDataBase_BigQuery_Signal_COPY.reset_index(inplace=True,drop=True)\n",
    "\n",
    "                                #PENDIENTE 15 MACD > 0\n",
    "                                candlesDataBase_BigQuery_Signal_COPY=candlesDataBase_BigQuery_Signal_COPY.loc[candlesDataBase_BigQuery_Signal_COPY.PENDIENTE_MACD_15>0]\n",
    "                                candlesDataBase_BigQuery_Signal_COPY.reset_index(inplace=True,drop=True)\n",
    "\n",
    "                                #RSI 30 ESTE POR DEBAJO DE 50\n",
    "                                candlesDataBase_BigQuery_Signal_COPY=candlesDataBase_BigQuery_Signal_COPY.loc[candlesDataBase_BigQuery_Signal_COPY.RSI_30<=float(rsi_30)]\n",
    "                                candlesDataBase_BigQuery_Signal_COPY.reset_index(inplace=True,drop=True)\n",
    "\n",
    "                                #PENDIENTE 30 MACD > 0\n",
    "                                candlesDataBase_BigQuery_Signal_COPY=candlesDataBase_BigQuery_Signal_COPY.loc[candlesDataBase_BigQuery_Signal_COPY.PENDIENTE_MACD_30>0]\n",
    "                                candlesDataBase_BigQuery_Signal_COPY.reset_index(inplace=True,drop=True)\n",
    "\n",
    "                                #RSI 60 ESTE POR DEBAJO DE 50\n",
    "                                candlesDataBase_BigQuery_Signal_COPY=candlesDataBase_BigQuery_Signal_COPY.loc[candlesDataBase_BigQuery_Signal_COPY.RSI_60<=float(rsi_60)]\n",
    "                                candlesDataBase_BigQuery_Signal_COPY.reset_index(inplace=True,drop=True)\n",
    "\n",
    "                                #PENDIENTE 60 MACD > 0\n",
    "                                candlesDataBase_BigQuery_Signal_COPY=candlesDataBase_BigQuery_Signal_COPY.loc[candlesDataBase_BigQuery_Signal_COPY.PENDIENTE_MACD_60>0]\n",
    "                                candlesDataBase_BigQuery_Signal_COPY.reset_index(inplace=True,drop=True)\n",
    "\n",
    "                                #\n",
    "\n",
    "                                #APPENDEAR COMPRA O NO COMRPA\n",
    "                                listaComprar=list(candlesDataBase_BigQuery_Signal_COPY.TIME.values)\n",
    "                                for i in list(test_sample.index.values):\n",
    "                                    if test_sample.at[i,\"TIME\"] in listaComprar:\n",
    "                                        test_sample.at[i,\"PRED\"]=\"SI\"\n",
    "                                    else:\n",
    "                                        test_sample.at[i,\"PRED\"]=\"NO\"\n",
    "\n",
    "                                #_____COPIAR BASE DE DATOS\n",
    "                                test_sample_copy=test_sample.copy()\n",
    "\n",
    "                                #_____SOBREESCRIBIR VARIABLE CLOSE CON VALORES REALES\n",
    "                                for back in range(0,len(test_sample_copy)):\n",
    "                                    test_sample_copy.at[back,\"CLOSE\"]=backtestingDataFrame.loc[backtestingDataFrame.TIME==test_sample_copy.at[back,\"TIME\"]][\"CLOSE\"].values[0]\n",
    "\n",
    "                                #_____CORREGIR PREDICTION\n",
    "                                predict=test_sample_copy[\"PRED\"]\n",
    "\n",
    "                                #_____INICIAR PARAMETROS\n",
    "                                date=test_sample_copy[\"TIME\"]\n",
    "                                close_price=test_sample_copy[\"CLOSE\"]\n",
    "\n",
    "                                #_____CREAR LIBRO DE TRADEO\n",
    "                                tradingBook=pd.DataFrame(columns=[\"DATE_BUY\",\"DATE_SELL\",\"NET_BUY_PRICE\",\"NET_SELL_PRICE\",\"STOP_LOSS\",\"NET_UTILITY\"])\n",
    "\n",
    "                                #_____PARAMETROS DE INICIO\n",
    "                                j=0\n",
    "                                ejecuto_compra=0\n",
    "\n",
    "                                #_____LOOP SEMI-INFINITO\n",
    "                                while j<=len(close_price)-2 :\n",
    "\n",
    "                                    #_____TRIGGER DE COMPRA\n",
    "                                    if predict[j] == \"SI\" :\n",
    "                                        buy_authorization = \"SI\"\n",
    "                                    else:\n",
    "                                        buy_authorization = \"NO\"\n",
    "\n",
    "                                    #_____SI TRIGGER DE COMPRA SE DISPARA\n",
    "                                    if buy_authorization == \"SI\":\n",
    "\n",
    "                                        #_____AGREGAR DATOS A LIBRO DE TRADEO + SUMAR UN POCO MAS DE FEES PARA AJUSTAR A VALORES REALES\n",
    "                                        time_buy=date[j]\n",
    "                                        index_row=len(tradingBook)\n",
    "                                        tradingBook.at[index_row,\"DATE_BUY\"]=time_buy\n",
    "                                        tradingBook.at[index_row,\"DATE_SELL\"]=\"\"\n",
    "                                        tradingBook.at[index_row,\"NET_BUY_PRICE\"]=close_price[j]*(1+0.001)\n",
    "\n",
    "                                        #_____LOOP INFINITO HASTA QUE SE EJECUTE VENTA\n",
    "                                        ejecuto_venta=0 \n",
    "                                        while ejecuto_venta==0 :\n",
    "\n",
    "                                            #_____SI PRECIO COMIENZA A CAER                \n",
    "                                            if (ejecuto_venta==0) and j<=(len(close_price)-2):\n",
    "\n",
    "                                                #_____ACTUALIZAR TIEMPO TRANSCURRIDO\n",
    "                                                j+=1\n",
    "\n",
    "                                                #_____ACTUALIZAR MARGEN DE VENTA + SUMAR UN POCO MAS DE FEES PARA AJUSTAR A VALORES REALES\n",
    "                                                margen_actual= ((close_price[j]*(1-0.001))/tradingBook.at[index_row,\"NET_BUY_PRICE\"])-1\n",
    "\n",
    "                                                #_____VENDER SI ESTOY ARRIBA DE MARGEN DE UTLIDAD\n",
    "                                                if (ejecuto_venta==0) and (margen_actual >= takeprofit):\n",
    "\n",
    "                                                    #_____EJECUTAR ORDEN DE VENTA\n",
    "                                                    ejecuto_venta=1\n",
    "\n",
    "                                                    #_____ACTUALIZAR BASE DE DATOS TRADINGBOOK_1\n",
    "                                                    tradingBook.at[index_row,\"DATE_SELL\"]=date[j]\n",
    "                                                    tradingBook.at[index_row,\"NET_SELL_PRICE\"]=(close_price[j]*(1-0.001))\n",
    "                                                    tradingBook.at[index_row,\"STOP_LOSS\"]=0\n",
    "                                                    tradingBook.at[index_row,\"NET_UTILITY\"]=(tradingBook.at[index_row,\"NET_SELL_PRICE\"]/tradingBook.at[index_row,\"NET_BUY_PRICE\"])-1\n",
    "\n",
    "                                                #_____SI PRECIO ESTA EN REGION DE STOPLOSS\n",
    "                                                elif (ejecuto_venta==0) and ((close_price[j] < tradingBook.at[index_row,\"NET_BUY_PRICE\"]*(1-stoploss+0.001))):\n",
    "\n",
    "                                                    #_____EJECUTAR ORDEN DE VENTA\n",
    "                                                    ejecuto_venta=1\n",
    "\n",
    "                                                    #_____ACTUALIZAR BASE DE DATOS TRADINGBOOK_1\n",
    "                                                    tradingBook.at[index_row,\"DATE_SELL\"]=date[j]\n",
    "                                                    tradingBook.at[index_row,\"NET_SELL_PRICE\"]=close_price[j]\n",
    "                                                    tradingBook.at[index_row,\"STOP_LOSS\"]=1\n",
    "                                                    tradingBook.at[index_row,\"NET_UTILITY\"]=((close_price[j]*(1-0.001))/tradingBook.at[index_row,\"NET_BUY_PRICE\"])-1\n",
    "\n",
    "                                            else:\n",
    "                                                ejecuto_venta=1\n",
    "\n",
    "                                    else:\n",
    "                                        #_____ACTUALIZAR TIEMPO TRANSCURRIDO\n",
    "                                        j+=1\n",
    "\n",
    "                                #_____AGREGAR DATOS A BASE DE DATOS DE UTILIDAD\n",
    "                                index_row=len(utility_df)\n",
    "                                utility_df.at[index_row,\"TP\"]=takeprofit\n",
    "                                utility_df.at[index_row,\"SL\"]=stoploss\n",
    "                                utility_df.at[index_row,\"DISTANCE\"]=distance[0]\n",
    "                                utility_df.at[index_row,\"ANGLE\"]=angle\n",
    "                                utility_df.at[index_row,\"RSI_15\"]=rsi_15\n",
    "                                utility_df.at[index_row,\"RSI_30\"]=rsi_30\n",
    "                                utility_df.at[index_row,\"RSI_60\"]=rsi_60\n",
    "                                utility_df.at[index_row,\"NET_UTILITY\"]=sum(tradingBook.dropna().NET_UTILITY)\n",
    "                                utility_df.at[index_row,\"LOSSES\"]=sum(tradingBook.STOP_LOSS)\n",
    "                                utility_df.at[index_row,\"WINNINGS\"]=len(tradingBook.loc[tradingBook.STOP_LOSS==0])\n",
    "                                \n",
    "    return utility_df\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCION QUE CREA PORTAFOLIO SEGUN LINEA DE EFICIENCIA DE PARETO\n",
    "def is_pareto_efficient(costs, return_mask = True):\n",
    "    \"\"\"\n",
    "    Find the pareto-efficient points\n",
    "    :param costs: An (n_points, n_costs) array\n",
    "    :param return_mask: True to return a mask\n",
    "    :return: An array of indices of pareto-efficient points.\n",
    "        If return_mask is True, this will be an (n_points, ) boolean array\n",
    "        Otherwise it will be a (n_efficient_points, ) integer array of indices.\n",
    "    \"\"\"\n",
    "    is_efficient = np.arange(costs.shape[0])\n",
    "    n_points = costs.shape[0]\n",
    "    next_point_index = 0  # Next index in the is_efficient array to search for\n",
    "    while next_point_index<len(costs):\n",
    "        nondominated_point_mask = np.any(costs>costs[next_point_index], axis=1)\n",
    "        nondominated_point_mask[next_point_index] = True\n",
    "        is_efficient = is_efficient[nondominated_point_mask]  # Remove dominated points\n",
    "        costs = costs[nondominated_point_mask]\n",
    "        next_point_index = np.sum(nondominated_point_mask[:next_point_index])+1\n",
    "    if return_mask:\n",
    "        is_efficient_mask = np.zeros(n_points, dtype = bool)\n",
    "        is_efficient_mask[is_efficient] = True\n",
    "        return is_efficient_mask\n",
    "    else:\n",
    "        return is_efficient\n",
    "    \n",
    "#_____\n",
    "\n",
    "#FUNCION QUE RETORNA MEJOR CONFIGURACION SEGUN PARETO\n",
    "def getPareto(backtesting_n):\n",
    "    \n",
    "    global backtesting_3\n",
    "    \n",
    "    updateConfig(\"semiManual.ini\")\n",
    "    \n",
    "    #_____PORTAFOLIO JERARQUICO\n",
    "    Pareto_df=backtesting_n.copy()\n",
    "    Pareto_df=Pareto_df.loc[(Pareto_df.LOSSES<=int(get_config(\"PARAMETERS_BACKTESTING\",\"MAX_LOSSES\")))&(Pareto_df.WINNINGS>len(candlesDataBase_BigQuery_Signal)*int(fractal)/60/24/7)].sort_values(by='NET_UTILITY', ascending=False)\n",
    "    Pareto_df.reset_index(inplace=True,drop=True)\n",
    "    Pareto_df=Pareto_df[[\"SL\",\"RSI_15\",\"RSI_30\",\"RSI_60\",\"NET_UTILITY\",\"LOSSES\",\"WINNINGS\"]]\n",
    "\n",
    "    Pareto_df[\"LOSSES\"]=Pareto_df[\"LOSSES\"]*(-1)\n",
    "    Pareto_df[\"SL\"]=Pareto_df[\"SL\"]*(-1)\n",
    "    Pareto_df[\"RSI_15\"]=Pareto_df[\"RSI_15\"]*(-1)\n",
    "    Pareto_df[\"RSI_30\"]=Pareto_df[\"RSI_30\"]*(-1)\n",
    "    Pareto_df[\"RSI_60\"]=Pareto_df[\"RSI_60\"]*(-1)\n",
    "\n",
    "    Pareto_df.reset_index(inplace=True,drop=True)\n",
    "    Efficient_market=is_pareto_efficient(np.array(Pareto_df), return_mask = False)\n",
    "    Pareto_df=Pareto_df.loc[list(Efficient_market),:]\n",
    "\n",
    "    Pareto_df[\"LOSSES\"]=Pareto_df[\"LOSSES\"]*(-1)\n",
    "    Pareto_df[\"SL\"]=Pareto_df[\"SL\"]*(-1)\n",
    "    Pareto_df[\"RSI_15\"]=Pareto_df[\"RSI_15\"]*(-1)\n",
    "    Pareto_df[\"RSI_30\"]=Pareto_df[\"RSI_30\"]*(-1)\n",
    "    Pareto_df[\"RSI_60\"]=Pareto_df[\"RSI_60\"]*(-1)\n",
    "    Pareto_df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    if len(Pareto_df)>0:\n",
    "        backtesting_3=backtesting_n.copy()\n",
    "        for i in list(Pareto_df.columns):\n",
    "            backtesting_3=backtesting_3.loc[backtesting_3[i]==Pareto_df.at[0,i]]\n",
    "        backtesting_3.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "        if len(backtesting_3)>1:\n",
    "            backtesting_3=backtesting_3.loc[backtesting_3.ANGLE==max(backtesting_3.ANGLE.values)]\n",
    "            backtesting_3.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        if len(backtesting_3)>1:\n",
    "            backtesting_3=backtesting_3.loc[backtesting_3.DISTANCE==max(backtesting_3.DISTANCE.values)]\n",
    "            backtesting_3.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        if len(backtesting_3)>1:\n",
    "            backtesting_3=backtesting_3[0:1]\n",
    "            backtesting_3.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        backtesting_3.at[0,\"NET_UTILITY\"]=round_decimals_down(backtesting_3.at[0,\"NET_UTILITY\"],3)\n",
    "    \n",
    "    else:\n",
    "        backtesting_3=Pareto_df.copy()\n",
    "        \n",
    "    return backtesting_3\n",
    "    \n",
    "#_____\n",
    "    \n",
    "#FINCION QUE FILTRA MERCADOS POTENCIALES POR VOLUMEN TRANSADO\n",
    "def marketList():\n",
    "    \n",
    "    #_____CONEXION BINANCE\n",
    "    binance = ccxt.binance()\n",
    "\n",
    "    #_____ACTUALIZAR ARCHIVO CONFIG PARA MERCADOS\n",
    "    updateConfig(\"semiManual.ini\")\n",
    "\n",
    "    #_____CREAR LISTA DE MERCADOS A EVALUAR\n",
    "    mercados_Portafolio_Bruto=[]\n",
    "    mercados=ast.literal_eval(get_config(\"DATABASES\",\"MARKETS\"))\n",
    "\n",
    "    #_____LISTA VOLUMEN MERCADOS\n",
    "    marketZeroVolumes_Prop=[]\n",
    "    marketAverVolumes_List=[]\n",
    "\n",
    "    #_____LISTA SAFE DE MERCADOS\n",
    "    safeList=[]\n",
    "    \n",
    "    #_____LISTA TOP DE MERCADOS CMC\n",
    "    cmc_Top_Market_List=topCoinMarketCap()\n",
    "\n",
    "    #_____RECORRER MERCADOS\n",
    "    for mercado in mercados:\n",
    "\n",
    "        #_____DESCARGAR BASE DE DATOS OLCV\n",
    "        #candlesDataBase_Binance = binance.fetch_ohlcv(mercado+\"/USDT\",\"1m\",limit=1000)\n",
    "        #candlesDataBase_Binance = candlesDataBase_Binance[:-1]\n",
    "\n",
    "        #_____PROPORCION MERCADO MUERTO\n",
    "        #contador_cero=0\n",
    "        #contador_aver=0\n",
    "        #for i in list(range(0,len(candlesDataBase_Binance))):\n",
    "        #    if candlesDataBase_Binance[i][5] == 0:\n",
    "        #        contador_cero=contador_cero+1\n",
    "        #    contador_aver=contador_aver+candlesDataBase_Binance[i][5]\n",
    "\n",
    "        #marketZeroVolumes_Prop.append(contador_cero/len(candlesDataBase_Binance))\n",
    "        #marketAverVolumes_List.append(contador_aver/len(candlesDataBase_Binance))\n",
    "\n",
    "        #_____ACTUALIZAR SAFE LIST\n",
    "        #if ((contador_cero/len(candlesDataBase_Binance)) == 0):\n",
    "        #    safeList.append(mercado)\n",
    "        \n",
    "        #_____SLEEP\n",
    "        #time.sleep(2)\n",
    "        \n",
    "        #_____AGEREGAR MERCADO SI ESTA EN TOP CMC\n",
    "        if mercado in cmc_Top_Market_List:\n",
    "            safeList.append(mercado)\n",
    "        \n",
    "\n",
    "    #_____NUEVA LISTA DE MERCADOS\n",
    "    return safeList\n",
    "\n",
    "#_____\n",
    "\n",
    "#FUNCION QUE GUARDA PDF COMO IMAGEN\n",
    "def render_mpl_table(data, col_width=3.0, row_height=0.625, font_size=14,\n",
    "                     header_color='#40466e', row_colors=['#f1f1f2', 'w'], edge_color='w',\n",
    "                     bbox=[0, 0, 1, 1], header_columns=0,\n",
    "                     ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
    "        fig, ax = plt.subplots(figsize=size)\n",
    "        ax.axis('off')\n",
    "    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)\n",
    "    mpl_table.auto_set_font_size(False)\n",
    "    mpl_table.set_fontsize(font_size)\n",
    "\n",
    "    for k, cell in mpl_table._cells.items():\n",
    "        cell.set_edgecolor(edge_color)\n",
    "        if k[0] == 0 or k[1] < header_columns:\n",
    "            cell.set_text_props(weight='bold', color='w')\n",
    "            cell.set_facecolor(header_color)\n",
    "        else:\n",
    "            cell.set_facecolor(row_colors[k[0]%len(row_colors) ])\n",
    "    return ax.get_figure(), ax\n",
    "\n",
    "#_____\n",
    "\n",
    "#TWITTER CONNECTION\n",
    "def OAuth():\n",
    "   \n",
    "    global auth\n",
    "    \n",
    "    updateConfig(\"semiManual.ini\")\n",
    "    \n",
    "    API_KEY=get_config(\"TWITTER\",\"API_KEY\")\n",
    "    API_SECRET_KEY=get_config(\"TWITTER\",\"API_SECRET_KEY\")\n",
    "    ACCESS_TOKEN=get_config(\"TWITTER\",\"ACCESS_TOKEN\")\n",
    "    ACCESS_TOKEN_SECRET=get_config(\"TWITTER\",\"ACCESS_TOKEN_SECRET\")\n",
    "   \n",
    "    \n",
    "    try:\n",
    "        auth = tw.OAuthHandler(API_KEY, API_SECRET_KEY)\n",
    "        auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "        return auth\n",
    "\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "#_____\n",
    "\n",
    "#FUNCION QUE DEVUELVE EL TOG X DE MERCADOS\n",
    "def topCoinMarketCap():\n",
    "    \n",
    "    updateConfig(\"semiManual.ini\")\n",
    "    \n",
    "    API_KEY_CAP=get_config(\"COINMARKETCAP\",\"API_KEY_CAP\")\n",
    "    url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
    "    parameters = {\n",
    "      'start':'1',\n",
    "      'limit': get_config(\"MARKETS\",\"TOP_CMC\"),\n",
    "      'convert':'USD'\n",
    "    }\n",
    "    headers = {\n",
    "      'Accepts': 'application/json',\n",
    "      'X-CMC_PRO_API_KEY': API_KEY_CAP,\n",
    "    }\n",
    "\n",
    "    session = Session()\n",
    "    session.headers.update(headers)\n",
    "\n",
    "    try:\n",
    "      response = session.get(url, params=parameters)\n",
    "      data = json.loads(response.text)\n",
    "      #print(data)\n",
    "    except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
    "      print(e)\n",
    "\n",
    "    response = pd.DataFrame(data[\"data\"])\n",
    "    response=list(response.symbol.values)\n",
    "\n",
    "    list_Avoid=[\"USDT\",\"USDC\",\"BUSD\",\"UST\",\"TUSD\",\"USDN\",\"LUSD\",\"HUSD\",\"OUSD\",\"GUSD\",\"USDX\",\"vUSDC,\"\"CUSD\",\"SUSD\",\"vBUSD,\"\"MUSD\",\"vUSDT,\"\"USDK\",\"USDJ\"]\n",
    "\n",
    "    for i in list_Avoid:\n",
    "        try:\n",
    "            response.remove(i)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9007af8d",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd019d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #_____CCXT\n",
    "# binance = ccxt.binance()\n",
    "\n",
    "# #_____GOOGLE CLOUD CONECTION\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/ubuntu/SurfNet/predictionModels/PREDICTION/bigQueryAccess.json\"\n",
    "\n",
    "# #_____UPDATE CONFIG PREDICTION\n",
    "# updateConfig(\"semiManual.ini\")\n",
    "\n",
    "# fractal=\"15\"\n",
    "# market_model=\"LUNA/USDT\"\n",
    "\n",
    "# _____CARGAR BASE DE DATOS\n",
    "# myData = binance.fetch_ohlcv(market_model,fractal+\"m\",limit=1000)\n",
    "# candlesDataBase_BigQuery =pd.DataFrame(columns=[\"ID\",\"TIME\",\"MARKET\",\"OPEN\",\"HIGH\",\"LOW\",\"CLOSE\",\"VOLUME\"])\n",
    "\n",
    "# for i in range(0,len(myData)):\n",
    "#     candlesDataBase_BigQuery.at[i,\"ID\"]=myData[i][0]\n",
    "#     candlesDataBase_BigQuery.at[i,\"TIME\"]=datetime.fromtimestamp(myData[i][0]/1000.0)\n",
    "#     candlesDataBase_BigQuery.at[i,\"MARKET\"]=market_model\n",
    "#     candlesDataBase_BigQuery.at[i,\"OPEN\"]=myData[i][1]\n",
    "#     candlesDataBase_BigQuery.at[i,\"HIGH\"]=myData[i][2]\n",
    "#     candlesDataBase_BigQuery.at[i,\"LOW\"]=myData[i][3]\n",
    "#     candlesDataBase_BigQuery.at[i,\"CLOSE\"]=myData[i][4]\n",
    "#     candlesDataBase_BigQuery.at[i,\"VOLUME\"]=myData[i][5]\n",
    "\n",
    "# # #_____CARGAR BASE DE DATOS\n",
    "# # market_model=market_model+\"_1M\"\n",
    "# # candlesDataBase_BigQuery=downloadDataBaseBigQuery(market_model,time=fractal,rows=int(get_config(\"PARAMETERS\",\"ROWS_DOWNLOAD\")))\n",
    "\n",
    "# #_____GUARDAR BASE DE DATOS PARA BACKTESTING FUTURO\n",
    "# backtestingDataFrame=candlesDataBase_BigQuery.copy()\n",
    "\n",
    "# #_____CREAR VARIABLES INPUT\n",
    "# candlesDataBase_BigQuery=variableCreation(candlesDataBase_BigQuery)\n",
    "\n",
    "# #_____CALCULAR PARA VELA DE 15\n",
    "# for i in range(1,max(candlesDataBase_BigQuery.index.values)+1):\n",
    "#     candlesDataBase_BigQuery.at[i,\"RSI_15\"]=candlesDataBase_BigQuery.at[i,\"RSI\"]\n",
    "#     candlesDataBase_BigQuery.at[i,\"HIST_MACD_VS_TRIGGER_15\"]=(candlesDataBase_BigQuery.at[i,\"MACD\"]-candlesDataBase_BigQuery.at[i,\"MACD_TRIGGER\"])\n",
    "#     candlesDataBase_BigQuery.at[i,\"PENDIENTE_MACD_15\"]=(candlesDataBase_BigQuery.at[i,\"MACD\"]-candlesDataBase_BigQuery.at[i-1,\"MACD\"])/int(fractal)\n",
    "#     candlesDataBase_BigQuery.at[i,\"PENDIENTE_MACD_TRIGGER_15\"]=(candlesDataBase_BigQuery.at[i,\"MACD_TRIGGER\"]-candlesDataBase_BigQuery.at[i-1,\"MACD_TRIGGER\"])/int(fractal)\n",
    "#     candlesDataBase_BigQuery.at[i,\"ANGLE_MACD_VS_TRIGGER_15\"]= np.arctan((candlesDataBase_BigQuery.at[i,\"PENDIENTE_MACD_15\"]-candlesDataBase_BigQuery.at[i,\"PENDIENTE_MACD_TRIGGER_15\"])/(1+candlesDataBase_BigQuery.at[i,\"PENDIENTE_MACD_15\"]*candlesDataBase_BigQuery.at[i,\"PENDIENTE_MACD_TRIGGER_15\"]))\n",
    "\n",
    "# #_____CALCULAR PARA VELA DE 30\n",
    "# fractal=\"30\"\n",
    "\n",
    "# #_____CARGAR BASE DE DATOS\n",
    "# myData = binance.fetch_ohlcv(market_model,fractal+\"m\",limit=1000)\n",
    "# candlesDataBase_BigQuery_2 =pd.DataFrame(columns=[\"ID\",\"TIME\",\"MARKET\",\"OPEN\",\"HIGH\",\"LOW\",\"CLOSE\",\"VOLUME\"])\n",
    "\n",
    "# for i in range(0,len(myData)):\n",
    "#     candlesDataBase_BigQuery_2.at[i,\"ID\"]=myData[i][0]\n",
    "#     candlesDataBase_BigQuery_2.at[i,\"TIME\"]=datetime.fromtimestamp(myData[i][0]/1000.0)\n",
    "#     candlesDataBase_BigQuery_2.at[i,\"MARKET\"]=market_model\n",
    "#     candlesDataBase_BigQuery_2.at[i,\"OPEN\"]=myData[i][1]\n",
    "#     candlesDataBase_BigQuery_2.at[i,\"HIGH\"]=myData[i][2]\n",
    "#     candlesDataBase_BigQuery_2.at[i,\"LOW\"]=myData[i][3]\n",
    "#     candlesDataBase_BigQuery_2.at[i,\"CLOSE\"]=myData[i][4]\n",
    "#     candlesDataBase_BigQuery_2.at[i,\"VOLUME\"]=myData[i][5]\n",
    "\n",
    "# # #_____CARGAR BASE DE DATOS\n",
    "# # candlesDataBase_BigQuery_2=downloadDataBaseBigQuery(market_model,time=fractal,rows=int(get_config(\"PARAMETERS\",\"ROWS_DOWNLOAD\")))\n",
    "\n",
    "# #_____GUARDAR BASE DE DATOS PARA BACKTESTING FUTURO\n",
    "# backtestingDataFrame_2=candlesDataBase_BigQuery_2.copy()\n",
    "\n",
    "# #_____CREAR VARIABLES INPUT\n",
    "# candlesDataBase_BigQuery_2=variableCreation(candlesDataBase_BigQuery_2)\n",
    "\n",
    "# #_____CALCULAR PARA VELA DE 15\n",
    "# for i in range(1,max(candlesDataBase_BigQuery_2.index.values)+1):\n",
    "#     candlesDataBase_BigQuery_2.at[i,\"RSI_30\"]=candlesDataBase_BigQuery_2.at[i,\"RSI\"]\n",
    "#     candlesDataBase_BigQuery_2.at[i,\"PENDIENTE_MACD_30\"]=(candlesDataBase_BigQuery_2.at[i,\"MACD\"]-candlesDataBase_BigQuery_2.at[i-1,\"MACD\"])/int(fractal)\n",
    "    \n",
    "# #_____CALCULAR PARA VELA DE 60\n",
    "# fractal=\"1h\"\n",
    "\n",
    "# #_____CARGAR BASE DE DATOS\n",
    "# myData = binance.fetch_ohlcv(market_model,fractal,limit=1000)\n",
    "# candlesDataBase_BigQuery_3 =pd.DataFrame(columns=[\"ID\",\"TIME\",\"MARKET\",\"OPEN\",\"HIGH\",\"LOW\",\"CLOSE\",\"VOLUME\"])\n",
    "\n",
    "# for i in range(0,len(myData)):\n",
    "#     candlesDataBase_BigQuery_3.at[i,\"ID\"]=myData[i][0]\n",
    "#     candlesDataBase_BigQuery_3.at[i,\"TIME\"]=datetime.fromtimestamp(myData[i][0]/1000.0)\n",
    "#     candlesDataBase_BigQuery_3.at[i,\"MARKET\"]=market_model\n",
    "#     candlesDataBase_BigQuery_3.at[i,\"OPEN\"]=myData[i][1]\n",
    "#     candlesDataBase_BigQuery_3.at[i,\"HIGH\"]=myData[i][2]\n",
    "#     candlesDataBase_BigQuery_3.at[i,\"LOW\"]=myData[i][3]\n",
    "#     candlesDataBase_BigQuery_3.at[i,\"CLOSE\"]=myData[i][4]\n",
    "#     candlesDataBase_BigQuery_3.at[i,\"VOLUME\"]=myData[i][5]\n",
    "\n",
    "# # #_____CARGAR BASE DE DATOS\n",
    "# # fractal=\"60\"\n",
    "# # candlesDataBase_BigQuery_3=downloadDataBaseBigQuery(market_model,time=fractal,rows=int(get_config(\"PARAMETERS\",\"ROWS_DOWNLOAD\")))\n",
    "\n",
    "# #_____GUARDAR BASE DE DATOS PARA BACKTESTING FUTURO\n",
    "# backtestingDataFrame_3=candlesDataBase_BigQuery_3.copy()\n",
    "\n",
    "# #_____CREAR VARIABLES INPUT\n",
    "# candlesDataBase_BigQuery_3=variableCreation(candlesDataBase_BigQuery_3)\n",
    "\n",
    "# #_____CALCULAR PARA VELA DE 15\n",
    "# for i in range(1,max(candlesDataBase_BigQuery_3.index.values)+1):\n",
    "#     candlesDataBase_BigQuery_3.at[i,\"RSI_60\"]=candlesDataBase_BigQuery_3.at[i,\"RSI\"]\n",
    "#     candlesDataBase_BigQuery_3.at[i,\"PENDIENTE_MACD_60\"]=(candlesDataBase_BigQuery_3.at[i,\"MACD\"]-candlesDataBase_BigQuery_3.at[i-1,\"MACD\"])/int(60)\n",
    "\n",
    "# #_____UNIR BASES DE DATOS\n",
    "# candlesDataBase_BigQuery=candlesDataBase_BigQuery[[\"TIME\",\"MARKET\",\"RSI_15\",\"HIST_MACD_VS_TRIGGER_15\",\"PENDIENTE_MACD_15\",\"ANGLE_MACD_VS_TRIGGER_15\"]]\n",
    "# candlesDataBase_BigQuery_2=candlesDataBase_BigQuery_2[[\"TIME\",\"RSI_30\",\"PENDIENTE_MACD_30\"]]\n",
    "# candlesDataBase_BigQuery_3=candlesDataBase_BigQuery_3[[\"TIME\",\"RSI_60\",\"PENDIENTE_MACD_60\"]]\n",
    "\n",
    "# candlesDataBase_BigQuery_Signal=pd.merge(candlesDataBase_BigQuery, candlesDataBase_BigQuery_2, on='TIME',how=\"left\")\n",
    "# candlesDataBase_BigQuery_Signal=pd.merge(candlesDataBase_BigQuery_Signal, candlesDataBase_BigQuery_3, on='TIME',how=\"left\")\n",
    "\n",
    "# candlesDataBase_BigQuery_Signal.fillna(method='ffill',inplace=True)\n",
    "# # candlesDataBase_BigQuery_Signal.dropna(inplace=True)\n",
    "# candlesDataBase_BigQuery_Signal=candlesDataBase_BigQuery_Signal[26*4:]\n",
    "# candlesDataBase_BigQuery_Signal.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b6a20a",
   "metadata": {},
   "source": [
    "GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8543e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #_____PARAMETROS\n",
    "# candlesDataBase_Graph=candlesDataBase_BigQuery_Signal.copy()\n",
    "# predType=\"PRED\"\n",
    "\n",
    "# #_____AGREGAR VARIABLE CLOSE\n",
    "# for i in range(0,len(candlesDataBase_Graph)):\n",
    "#     candlesDataBase_Graph.at[i,\"CLOSE\"]=backtestingDataFrame.loc[backtestingDataFrame.TIME==candlesDataBase_Graph.at[i,\"TIME\"]][\"CLOSE\"].values[0]\n",
    "\n",
    "# #_____AGREGAR COLORES\n",
    "# candlesDataBase_Color=candlesDataBase_Graph.copy()\n",
    "# candlesDataBase_Color=candlesDataBase_Color[[predType]]\n",
    "# candlesDataBase_Color=np.where(candlesDataBase_Color[predType] ==\"SI\", \"red\", \"blue\")\n",
    "\n",
    "# #_____DAR TEXTO A EJES\n",
    "# x_buy = candlesDataBase_Graph[[\"TIME\"]].values\n",
    "# y_buy = candlesDataBase_Graph[[\"CLOSE\"]].values\n",
    "# color_buy = candlesDataBase_Color\n",
    "\n",
    "# #_____RESETEAR\n",
    "# fig_buy = None\n",
    "\n",
    "# #_____IMPRIMIR GRAFICA\n",
    "# fig_buy = plt.figure(1, figsize=(20,10))\n",
    "# ax_buy  = fig_buy.add_subplot(111)\n",
    "# plot_colourline(x_buy,y_buy,color_buy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deb8cd7",
   "metadata": {},
   "source": [
    "# CHECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42491055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "926d5b27",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_____OPENMARKETS\n",
    "openMarkets_Long=[]\n",
    "writePickleVariable(openMarkets_Long,\"openMarkets_Long\")\n",
    "openMarkets_Short=[]\n",
    "writePickleVariable(openMarkets_Short,\"openMarkets_Short\")\n",
    "\n",
    "#_____TWITTED MARKETS\n",
    "openMarkets_Short_Twitted=[]\n",
    "writePickleVariable(openMarkets_Short_Twitted,\"openMarkets_Short_Twitted\")\n",
    "openMarkets_Long_Twitted=[]\n",
    "writePickleVariable(openMarkets_Long_Twitted,\"openMarkets_Long_Twitted\")\n",
    "\n",
    "#_____LOOP INFINITO\n",
    "while True:\n",
    "    \n",
    "    #_____TRY DE CONTINGENCIA\n",
    "    try:\n",
    "    \n",
    "        #_____CONEXION BINANCE\n",
    "        binance = ccxt.binance()\n",
    "\n",
    "        #_____UPDATE CONFIG PREDICTION\n",
    "        updateConfig(\"semiManual.ini\")\n",
    "\n",
    "        #_____MARKET LIST DE MERCADOS POTENCIALES\n",
    "        marketsIterationList=marketList()\n",
    "        random.shuffle(marketsIterationList)\n",
    "\n",
    "        #_____FOR LOOP PARA ITERACION DE ALERTA DE MERCADOS\n",
    "        for market in marketsIterationList:\n",
    "\n",
    "            #_____PRINT WITNESS\n",
    "            clear_output()\n",
    "            market_model=market+\"/USDT\"\n",
    "            print(market+\"/USDT\",str(datetime.now()-timedelta(hours=5)))\n",
    "\n",
    "            #_____CALCULAR PARA VELA DE 4H\n",
    "            fractal=\"4h\"\n",
    "\n",
    "            #_____CARGAR BASE DE DATOS\n",
    "            myData = binance.fetch_ohlcv(market_model,fractal,limit=1000)\n",
    "            candlesDataBase_BigQuery_4H =pd.DataFrame(columns=[\"ID\",\"TIME\",\"MARKET\",\"OPEN\",\"HIGH\",\"LOW\",\"CLOSE\",\"VOLUME\"])\n",
    "\n",
    "            for i in range(0,len(myData)):\n",
    "                candlesDataBase_BigQuery_4H.at[i,\"ID\"]=myData[i][0]\n",
    "                candlesDataBase_BigQuery_4H.at[i,\"TIME\"]=datetime.fromtimestamp(myData[i][0]/1000.0)\n",
    "                candlesDataBase_BigQuery_4H.at[i,\"MARKET\"]=market_model\n",
    "                candlesDataBase_BigQuery_4H.at[i,\"OPEN\"]=myData[i][1]\n",
    "                candlesDataBase_BigQuery_4H.at[i,\"HIGH\"]=myData[i][2]\n",
    "                candlesDataBase_BigQuery_4H.at[i,\"LOW\"]=myData[i][3]\n",
    "                candlesDataBase_BigQuery_4H.at[i,\"CLOSE\"]=myData[i][4]\n",
    "                candlesDataBase_BigQuery_4H.at[i,\"VOLUME\"]=myData[i][5]\n",
    "\n",
    "            #_____CREAR VARIABLES INPUT\n",
    "            candlesDataBase_BigQuery_4H=variableCreation(candlesDataBase_BigQuery_4H)\n",
    "\n",
    "            #_____CALCULAR PARA VELA DE 4H\n",
    "            for i in range(1,max(candlesDataBase_BigQuery_4H.index.values)+1):\n",
    "                candlesDataBase_BigQuery_4H.at[i,\"HIST_MACD_VS_TRIGGER_4H\"]=(candlesDataBase_BigQuery_4H.at[i,\"MACD\"]-candlesDataBase_BigQuery_4H.at[i,\"MACD_TRIGGER\"])\n",
    "\n",
    "            #_____SI MERCADO SE ABRE PARA LONG\n",
    "            openMarkets_Long_Twitted=readPickleVariable(\"openMarkets_Long_Twitted\")\n",
    "            if market in openMarkets_Long_Twitted:\n",
    "                if candlesDataBase_BigQuery_4H.at[len(candlesDataBase_BigQuery_4H)-1,\"HIST_MACD_VS_TRIGGER_4H\"]>0:\n",
    "                    openMarkets_Long_Twitted.remove(market)\n",
    "                    writePickleVariable(openMarkets_Long_Twitted,\"openMarkets_Long_Twitted\")\n",
    "            if market not in openMarkets_Long_Twitted:\n",
    "                if candlesDataBase_BigQuery_4H.at[len(candlesDataBase_BigQuery_4H)-1,\"HIST_MACD_VS_TRIGGER_4H\"]<0:\n",
    "                    if candlesDataBase_BigQuery_4H.at[len(candlesDataBase_BigQuery_4H)-2,\"HIST_MACD_VS_TRIGGER_4H\"]<candlesDataBase_BigQuery_4H.at[len(candlesDataBase_BigQuery_4H)-1,\"HIST_MACD_VS_TRIGGER_4H\"]:\n",
    "                        if candlesDataBase_BigQuery_4H.at[len(candlesDataBase_BigQuery_4H)-3,\"HIST_MACD_VS_TRIGGER_4H\"]<candlesDataBase_BigQuery_4H.at[len(candlesDataBase_BigQuery_4H)-2,\"HIST_MACD_VS_TRIGGER_4H\"]:\n",
    "                            openMarkets_Long=readPickleVariable(\"openMarkets_Long\")\n",
    "                            if market not in openMarkets_Long:\n",
    "                                openMarkets_Long.append(market)\n",
    "                                writePickleVariable(openMarkets_Long,\"openMarkets_Long\")\n",
    "\n",
    "            #_____SI MERCADO SE ABRE PARA SHORT\n",
    "            openMarkets_Short_Twitted=readPickleVariable(\"openMarkets_Short_Twitted\")\n",
    "            if market in openMarkets_Short_Twitted:\n",
    "                if candlesDataBase_BigQuery_4H.at[len(candlesDataBase_BigQuery_4H)-1,\"HIST_MACD_VS_TRIGGER_4H\"]<0:\n",
    "                    openMarkets_Short_Twitted.remove(market)\n",
    "                    writePickleVariable(openMarkets_Short_Twitted,\"openMarkets_Short_Twitted\")\n",
    "            if market not in openMarkets_Short_Twitted:\n",
    "                if candlesDataBase_BigQuery_4H.at[len(candlesDataBase_BigQuery_4H)-1,\"HIST_MACD_VS_TRIGGER_4H\"]>0:\n",
    "                    if candlesDataBase_BigQuery_4H.at[len(candlesDataBase_BigQuery_4H)-2,\"HIST_MACD_VS_TRIGGER_4H\"]>candlesDataBase_BigQuery_4H.at[len(candlesDataBase_BigQuery_4H)-1,\"HIST_MACD_VS_TRIGGER_4H\"]:\n",
    "                        if candlesDataBase_BigQuery_4H.at[len(candlesDataBase_BigQuery_4H)-3,\"HIST_MACD_VS_TRIGGER_4H\"]>candlesDataBase_BigQuery_4H.at[len(candlesDataBase_BigQuery_4H)-2,\"HIST_MACD_VS_TRIGGER_4H\"]:\n",
    "                            openMarkets_Short=readPickleVariable(\"openMarkets_Short\")\n",
    "                            if market not in openMarkets_Short:\n",
    "                                openMarkets_Short.append(market)\n",
    "                                writePickleVariable(openMarkets_Short,\"openMarkets_Short\")\n",
    "\n",
    "            #_____SLEEP\n",
    "            time.sleep(20)\n",
    "            clear_output()\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        #_____PRINT\n",
    "        print(\"[[ERROR]]\")\n",
    "        time.sleep(300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
